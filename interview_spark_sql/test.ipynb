{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c8050315",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25b778fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import Row"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a497b6b",
   "metadata": {},
   "source": [
    "# Create Spark Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3fbca643",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/04/11 21:06:05 WARN Utils: Your hostname, kampootar resolves to a loopback address: 127.0.1.1; using 192.168.1.9 instead (on interface enp8s0)\n",
      "25/04/11 21:06:05 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/04/11 21:06:05 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7d6c60d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----------+---------+\n",
      "|key| first_name|last_name|\n",
      "+---+-----------+---------+\n",
      "|  1|Christopher|   Wilson|\n",
      "|  2|   Jennifer| Martinez|\n",
      "|  3|    Michael| Anderson|\n",
      "|  4|      Sarah|   Taylor|\n",
      "|  5|      David|   Thomas|\n",
      "|  6|      Emily|Hernandez|\n",
      "|  7|      James|    Moore|\n",
      "|  8|    Jessica|  Jackson|\n",
      "|  9|    William|   Martin|\n",
      "| 10|     Ashley|      Lee|\n",
      "| 41|    Brandon|    Perez|\n",
      "| 42|   Samantha|    White|\n",
      "| 43|     Joseph|   Harris|\n",
      "| 44|      Megan|  Sanchez|\n",
      "| 45|       Ryan|    Clark|\n",
      "| 46|   Kimberly|  Ramirez|\n",
      "| 47|   Nicholas|    Lewis|\n",
      "| 48|     Amanda|   Walker|\n",
      "| 49|     Daniel|    Young|\n",
      "| 50|  Stephanie|     King|\n",
      "+---+-----------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = [\n",
    "    (1, 'Christopher', 'Wilson'),\n",
    "    (2, 'Jennifer', 'Martinez'),\n",
    "    (3, 'Michael', 'Anderson'),\n",
    "    (4, 'Sarah', 'Taylor'),\n",
    "    (5, 'David', 'Thomas'),\n",
    "    (6, 'Emily', 'Hernandez'),\n",
    "    (7, 'James', 'Moore'),\n",
    "    (8, 'Jessica', 'Jackson'),\n",
    "    (9, 'William', 'Martin'),\n",
    "    (10, 'Ashley', 'Lee'),\n",
    "    (41, 'Brandon', 'Perez'),\n",
    "    (42, 'Samantha', 'White'),\n",
    "    (43, 'Joseph', 'Harris'),\n",
    "    (44, 'Megan', 'Sanchez'),\n",
    "    (45, 'Ryan', 'Clark'),\n",
    "    (46, 'Kimberly', 'Ramirez'),\n",
    "    (47, 'Nicholas', 'Lewis'),\n",
    "    (48, 'Amanda', 'Walker'),\n",
    "    (49, 'Daniel', 'Young'),\n",
    "    (50, 'Stephanie', 'King')\n",
    "]\n",
    "\n",
    "my_df = spark.createDataFrame(data, schema=[\"key\", \"first_name\", \"last_name\"])\n",
    "\n",
    "my_df.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
