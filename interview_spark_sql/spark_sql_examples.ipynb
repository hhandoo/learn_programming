{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a8618d53",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "5ab22c62",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession, Window, WindowSpec\n",
    "from pyspark.sql.types import StringType, IntegerType, DateType, BooleanType, StructType, StructField, TimestampType, DoubleType\n",
    "from pyspark.sql.functions import col, min, max, lead, lag, rank, dense_rank, expr, minute, unix_timestamp, month, day, when, sum, date_trunc, date_diff\n",
    "from faker import Faker\n",
    "from datetime import datetime\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "789c4d0e",
   "metadata": {},
   "source": [
    "# My Spark Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "70eedad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.getOrCreate()\n",
    "fake = Faker()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2572d60d",
   "metadata": {},
   "source": [
    "# Generate Test DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "10f6f61e",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_records = 50\n",
    "data = [\n",
    "    (\n",
    "        i + 1,                      # id\n",
    "        fake.first_name(),          # first_name\n",
    "        fake.last_name(),           # last_name\n",
    "        random.randint(18, 80),     # age\n",
    "        fake.email(),               # email\n",
    "        fake.city()                 # city\n",
    "    )\n",
    "    for i in range(num_records)\n",
    "]\n",
    "columns = [\"id\", \"first_name\", \"last_name\", \"age\", \"email\", \"city\"]\n",
    "\n",
    "test_data_frame = spark.createDataFrame(data, schema = columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "7b44166e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+----------+---+--------------------+------------------+\n",
      "| id|first_name| last_name|age|               email|              city|\n",
      "+---+----------+----------+---+--------------------+------------------+\n",
      "|  1|   Deborah|Cunningham| 36|  wwhite@example.com|North Brianborough|\n",
      "|  2|     Linda|  Anderson| 24|angela28@example.net|     Chambersburgh|\n",
      "|  3|  Samantha|    Dorsey| 54|jonestracy@exampl...|       Williamfort|\n",
      "|  4|   Adriana|     Brown| 69|  paul11@example.net|   Lake Janicestad|\n",
      "|  5|      Paul|     Chang| 74|dawnstevens@examp...|        South Jose|\n",
      "|  6|       Ann|    Walker| 19|robinsonjulie@exa...|          Reedfurt|\n",
      "|  7|  Courtney|   Freeman| 67|  gchung@example.org|         Jamestown|\n",
      "|  8|     Danny|   Alvarez| 60|baileyjoshua@exam...|     Martinborough|\n",
      "|  9|     Scott|  Williams| 41|zjohnson@example.org|          New Mark|\n",
      "| 10|      Mark|   Johnson| 75|  hbrown@example.com|      South Denise|\n",
      "| 11|    Bailey|   Johnson| 34|donaldriley@examp...|       Ashleyshire|\n",
      "| 12|  Brittany|   Spencer| 26|awilliams@example...|       Port Denise|\n",
      "| 13| Alejandra|   Perkins| 68|fletchermiranda@e...|       Timothyview|\n",
      "| 14|  Nicholas|       Lee| 19|jessicamartinez@e...| West Jessicaville|\n",
      "| 15|      Mark|     Green| 51|samantha69@exampl...|         Tonyaport|\n",
      "| 16|   Lindsay|    Thomas| 25|tiffanylynch@exam...|   West Robertstad|\n",
      "| 17|     Peggy| Macdonald| 45|brianhoward@examp...|        Lake Jason|\n",
      "| 18|    Ronald|    Taylor| 30|hawkinsanna@examp...|          Toddtown|\n",
      "| 19|   Melissa|     Baker| 63|allenbrian@exampl...|Lake Daniellemouth|\n",
      "| 20|    Victor|     Scott| 42|lewissteven@examp...|       Hannahmouth|\n",
      "+---+----------+----------+---+--------------------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_data_frame.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34a7190a",
   "metadata": {},
   "source": [
    "# Repeated Payments [Stripe SQL Interview Question]\n",
    "Stripe asked this tricky SQL interview question, about identifying any payments made at the same merchant with the same credit card for the same amount within 10 minutes of each other and reporting the count of such repeated payments.\n",
    "\n",
    "- same merchant\n",
    "- same credit card\n",
    "- same amount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "08df4762",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = StructType([\n",
    "    StructField(\"transaction_id\", IntegerType(), True),\n",
    "    StructField(\"merchant_id\", IntegerType(), True),\n",
    "    StructField(\"credit_card_id\", IntegerType(), True),\n",
    "    StructField(\"amount\", IntegerType(), True),\n",
    "    StructField(\"transaction_timestamp\", TimestampType(), True)\n",
    "])\n",
    "\n",
    "data = [\n",
    "    (1, 101, 1, 100, datetime.strptime('09/25/2022 12:00:00', '%m/%d/%Y %H:%M:%S')),\n",
    "    (2, 101, 1, 100, datetime.strptime('09/25/2022 12:08:00', '%m/%d/%Y %H:%M:%S')),\n",
    "    (3, 101, 1, 100, datetime.strptime('09/25/2022 12:28:00', '%m/%d/%Y %H:%M:%S')),\n",
    "    (4, 102, 2, 300, datetime.strptime('09/25/2022 12:00:00', '%m/%d/%Y %H:%M:%S')),\n",
    "    (6, 102, 2, 400, datetime.strptime('09/25/2022 14:00:00', '%m/%d/%Y %H:%M:%S'))\n",
    "]\n",
    "question_1 = spark.createDataFrame(data, schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "1c426a66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "window_spec = Window.partitionBy([\"merchant_id\", \"credit_card_id\", \"amount\"]).orderBy(\"transaction_timestamp\")\n",
    "answer_1 = question_1\\\n",
    ".withColumn('prev_time', lag(\"transaction_timestamp\").over(window_spec))\\\n",
    ".withColumn('time_diff',  (unix_timestamp(col('transaction_timestamp')) - unix_timestamp(col('prev_time'))) / 60)\\\n",
    ".filter(\"time_diff<=10\")\n",
    "answer_1.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b20f144",
   "metadata": {},
   "source": [
    "## SQL Query\n",
    "\n",
    "```sql\n",
    "\n",
    "WITH\n",
    "  payments AS (\n",
    "    SELECT\n",
    "      *,\n",
    "    EXTRACT(EPOCH FROM \n",
    "\n",
    "            transaction_timestamp - LAG(transaction_timestamp) \n",
    "            \n",
    "            OVER (PARTITION BY merchant_id, credit_card_id, amount ORDER BY transaction_timestamp)\n",
    "            \n",
    "            )/60\n",
    "            AS minute_difference\n",
    "    FROM\n",
    "      transactions\n",
    "  )\n",
    "SELECT\n",
    "  COUNT(merchant_id) AS payment_count\n",
    "FROM\n",
    "  payments\n",
    "WHERE\n",
    "  minute_difference <= 10;\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "598721b1",
   "metadata": {},
   "source": [
    "## Alternate solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "cc91ff0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+-----------+--------------+------+---------------------+--------------+-----------+--------------+------+---------------------+\n",
      "|transaction_id|merchant_id|credit_card_id|amount|transaction_timestamp|transaction_id|merchant_id|credit_card_id|amount|transaction_timestamp|\n",
      "+--------------+-----------+--------------+------+---------------------+--------------+-----------+--------------+------+---------------------+\n",
      "|             1|        101|             1|   100|  2022-09-25 12:00:00|             2|        101|             1|   100|  2022-09-25 12:08:00|\n",
      "+--------------+-----------+--------------+------+---------------------+--------------+-----------+--------------+------+---------------------+\n",
      "\n",
      "Repeated payments within 10 minutes: 1\n"
     ]
    }
   ],
   "source": [
    "# Self-join the DataFrame with itself\n",
    "df_alias1 = question_1.alias(\"t1\")\n",
    "df_alias2 = question_1.alias(\"t2\")\n",
    "\n",
    "# Join with conditions\n",
    "joined = df_alias1.join(\n",
    "    df_alias2,\n",
    "    (col(\"t1.merchant_id\") == col(\"t2.merchant_id\")) &\n",
    "    (col(\"t1.credit_card_id\") == col(\"t2.credit_card_id\")) &\n",
    "    (col(\"t1.amount\") == col(\"t2.amount\")) &\n",
    "\n",
    "    (col(\"t2.transaction_timestamp\") > col(\"t1.transaction_timestamp\")) &\n",
    "    (col(\"t2.transaction_timestamp\") <= expr(\"t1.transaction_timestamp + interval 10 minutes\")),\n",
    "    \n",
    "    how = \"inner\"\n",
    ")\n",
    "\n",
    "# Count repeated payments\n",
    "repeated_count = joined.count()\n",
    "\n",
    "joined.show()\n",
    "\n",
    "print(\"Repeated payments within 10 minutes:\", repeated_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db900f9d",
   "metadata": {},
   "source": [
    "## SQL Query\n",
    "\n",
    "```sql\n",
    "select\n",
    "  count(*)\n",
    "from\n",
    "  transactions as t1\n",
    "  inner join transactions as t2 on t1.merchant_id = t2.merchant_id\n",
    "  AND t1.credit_card_id = t2.credit_card_id\n",
    "  AND t1.amount = t2.amount\n",
    "  AND t2.transaction_timestamp > t1.transaction_timestamp\n",
    "  AND t2.transaction_timestamp <= t1.transaction_timestamp + INTERVAL '10 minute';\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74106a4d",
   "metadata": {},
   "source": [
    "# Recursive CTE Example\n",
    "\n",
    "```sql\n",
    "WITH RECURSIVE EmployeeHierarchy AS (\n",
    "    -- Anchor member: Select the top-level employee(s)\n",
    "    SELECT EmployeeID, FirstName, LastName, ManagerID, 0 AS Level\n",
    "    FROM Employees\n",
    "    WHERE ManagerID IS NULL -- Assuming the top manager has NULL ManagerID\n",
    "\n",
    "    UNION ALL\n",
    "\n",
    "    -- Recursive member: Join with the CTE itself to find subordinates\n",
    "    SELECT e.EmployeeID, e.FirstName, e.LastName, e.ManagerID, eh.Level + 1\n",
    "    FROM Employees e\n",
    "    INNER JOIN EmployeeHierarchy eh ON e.ManagerID = eh.EmployeeID\n",
    ")\n",
    "SELECT *\n",
    "FROM EmployeeHierarchy\n",
    "ORDER BY Level, FirstName;\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dcbdfc8",
   "metadata": {},
   "source": [
    "# Median Google Search Frequency [Google SQL Interview Question]\n",
    "\n",
    "Googleâ€™s Marketing Team needed to add a simple statistic to their upcoming Superbowl Ad: the median number of searches made per year. You were given a summary table that tells you the number of searches made last year, write a query to report the median searches made per user.\n",
    "\n",
    "```sql\n",
    "WITH RECURSIVE expanded AS (\n",
    "    -- Initialize the recursion with the original data\n",
    "    SELECT searches, num_users, 1 AS user_index\n",
    "    FROM searches\n",
    "    WHERE num_users > 0\n",
    "\n",
    "    UNION ALL\n",
    "\n",
    "    -- Recursively add rows based on num_users\n",
    "    SELECT e.searches, e.num_users, e.user_index + 1\n",
    "    FROM expanded e\n",
    "    WHERE e.user_index + 1 <= e.num_users\n",
    "),\n",
    "ordered AS (\n",
    "  SELECT \n",
    "  searches, \n",
    "  ROW_NUMBER() OVER (ORDER BY searches) AS rn,\n",
    "  COUNT(*) OVER () AS total_users\n",
    "  FROM expanded\n",
    ")\n",
    "SELECT\n",
    "    round(AVG(searches)::NUMERIC, 2) AS median\n",
    "FROM ordered\n",
    "WHERE rn IN (total_users/2, total_users/2 + 2);\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fb9064b",
   "metadata": {},
   "source": [
    "# Monthly Merchant Balance [Visa SQL Interview Question]\n",
    "Say you have access to all the transactions for a given merchant account. Write a query to print the cumulative balance of the merchant account at the end of each day, with the total balance reset back to zero at the end of the month. Output the transaction date and cumulative balance.\n",
    "\n",
    "\n",
    "\n",
    "```sql\n",
    "WITH daily_balances AS (\n",
    "  SELECT\n",
    "    DATE_TRUNC('day', transaction_date) AS transaction_day,\n",
    "    DATE_TRUNC('month', transaction_date) AS transaction_month,\n",
    "    SUM(CASE WHEN type = 'deposit' THEN amount\n",
    "      WHEN type = 'withdrawal' THEN -amount END) AS balance\n",
    "  FROM visatransactions\n",
    "  GROUP BY \n",
    "    DATE_TRUNC('day', transaction_date),\n",
    "    DATE_TRUNC('month', transaction_date)\n",
    ")\n",
    "\n",
    "SELECT\n",
    "  transaction_day,\n",
    "  SUM(balance) OVER (\n",
    "    PARTITION BY transaction_month\n",
    "    ORDER BY transaction_day) AS balance\n",
    "FROM daily_balances\n",
    "ORDER BY transaction_day;\n",
    "```\n",
    "\n",
    "Hint\n",
    "\n",
    "    Row\tCumulative Sum\n",
    "    1\t106.66\n",
    "    2\t106.66 + 98.50 = 205.16\n",
    "    3\t106.66 + 98.50 + 50.00 = 255.16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "f7919777",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = StructType([\n",
    "    StructField(\"transaction_id\", IntegerType(), True),\n",
    "    StructField(\"type\", StringType(), True),\n",
    "    StructField(\"amount\", DoubleType(), True),\n",
    "    StructField(\"transaction_date\", TimestampType(), True)\n",
    "])\n",
    "\n",
    "data = [\n",
    "    (19153, 'deposit', 65.90, datetime.strptime('07/10/2022 10:00:00', '%m/%d/%Y %H:%M:%S')),\n",
    "    (53151, 'deposit', 178.55, datetime.strptime('07/08/2022 10:00:00', '%m/%d/%Y %H:%M:%S')),\n",
    "    (29776, 'withdrawal', 25.90, datetime.strptime('07/08/2022 10:00:00', '%m/%d/%Y %H:%M:%S')),\n",
    "    (16461, 'withdrawal', 45.99, datetime.strptime('07/08/2022 10:00:00', '%m/%d/%Y %H:%M:%S')),\n",
    "    (77134, 'deposit', 32.60, datetime.strptime('07/10/2022 10:00:00', '%m/%d/%Y %H:%M:%S'))\n",
    "]\n",
    "\n",
    "\n",
    "question_3 = spark.createDataFrame(data, schema=schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "7065fffb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+----------+------+-------------------+\n",
      "|transaction_id|      type|amount|   transaction_date|\n",
      "+--------------+----------+------+-------------------+\n",
      "|         19153|   deposit|  65.9|2022-07-10 10:00:00|\n",
      "|         53151|   deposit|178.55|2022-07-08 10:00:00|\n",
      "|         29776|withdrawal|  25.9|2022-07-08 10:00:00|\n",
      "|         16461|withdrawal| 45.99|2022-07-08 10:00:00|\n",
      "|         77134|   deposit|  32.6|2022-07-10 10:00:00|\n",
      "+--------------+----------+------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "question_3.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "481133cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-------------------+-------+\n",
      "|              month|                day|balance|\n",
      "+-------------------+-------------------+-------+\n",
      "|2022-07-01 00:00:00|2022-07-10 00:00:00|   98.5|\n",
      "|2022-07-01 00:00:00|2022-07-08 00:00:00| 106.66|\n",
      "+-------------------+-------------------+-------+\n",
      "\n",
      "+-------------------+-------+\n",
      "|                day|balance|\n",
      "+-------------------+-------+\n",
      "|2022-07-08 00:00:00| 106.66|\n",
      "|2022-07-10 00:00:00| 205.16|\n",
      "+-------------------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "question_3_group1 = question_3\\\n",
    "    .withColumn('month', date_trunc(\"month\", col(\"transaction_date\")))\\\n",
    "    .withColumn('day', date_trunc(\"day\", col(\"transaction_date\")))\n",
    "\n",
    "question_3_group1 = question_3_group1.groupBy([\"month\", \"day\"]).agg(\n",
    "    sum(\n",
    "        when(\n",
    "            col(\"type\") == \"deposit\", \n",
    "            col(\"amount\")\n",
    "        ).otherwise(\n",
    "            -1*col(\"amount\")\n",
    "        )\n",
    "        ).alias(\"balance\")\n",
    ")\n",
    "question_3_window = Window.partitionBy(\"month\").orderBy(\"day\")\n",
    "question_3_group1.show()\n",
    "answer_3 = question_3_group1.withColumn(\n",
    "    \"balance\", sum(\"balance\").over(question_3_window)) \\\n",
    "    .select(\"day\", \"balance\") \\\n",
    "    .orderBy(\"day\")\n",
    "\n",
    "answer_3.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b81217f",
   "metadata": {},
   "source": [
    "# Server Utilization Time [Amazon SQL Interview Question]\n",
    "\n",
    "Fleets of servers power Amazon Web Services (AWS). Senior management has requested data-driven solutions to optimize server usage.\n",
    "\n",
    "Write a query that calculates the total time that the fleet of servers was running. The output should be in units of full days.\n",
    "\n",
    "Assumptions:\n",
    "\n",
    "- Each server might start and stop several times.\n",
    "- The total time in which the server fleet is running can be calculated as the sum of each server's uptime.\n",
    "\n",
    "\n",
    "``` sql\n",
    "with running_time as  (\n",
    "  select \n",
    "  server_id,\n",
    "  session_status,\n",
    "  status_time AS start_time,\n",
    "  LEAD(status_time) OVER(partition by server_id order by status_time) as stop_time\n",
    "  from server_utilization\n",
    ")\n",
    "SELECT \n",
    "DATE_PART('days', JUSTIFY_HOURS(SUM(stop_time - start_time))) AS total_uptime_days\n",
    "FROM running_time\n",
    "WHERE session_status = 'start' AND stop_time IS NOT NULL;\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "7d98c1ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-------------------+--------------+\n",
      "|server_id|        status_time|session_status|\n",
      "+---------+-------------------+--------------+\n",
      "|        1|2022-08-02 10:00:00|         start|\n",
      "|        1|2022-08-04 10:00:00|          stop|\n",
      "|        2|2022-08-17 10:00:00|         start|\n",
      "|        2|2022-08-24 10:00:00|          stop|\n",
      "+---------+-------------------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "schema = StructType([\n",
    "    StructField(\"server_id\", IntegerType(), True),\n",
    "    StructField(\"status_time\", TimestampType(), True),\n",
    "    StructField(\"session_status\", StringType(), True)\n",
    "])\n",
    "\n",
    "# Create the data\n",
    "data = [\n",
    "    (1, datetime.strptime(\"2022-08-02 10:00:00\", \"%Y-%m-%d %H:%M:%S\"), \"start\"),\n",
    "    (1, datetime.strptime(\"2022-08-04 10:00:00\", \"%Y-%m-%d %H:%M:%S\"), \"stop\"),\n",
    "    (2, datetime.strptime(\"2022-08-17 10:00:00\", \"%Y-%m-%d %H:%M:%S\"), \"start\"),\n",
    "    (2, datetime.strptime(\"2022-08-24 10:00:00\", \"%Y-%m-%d %H:%M:%S\"), \"stop\")\n",
    "]\n",
    "\n",
    "question_4 = spark.createDataFrame(data, schema)\n",
    "\n",
    "question_4.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "d962de49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n",
      "|total_diff|\n",
      "+----------+\n",
      "|         9|\n",
      "+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "question_4_window = Window.partitionBy(\"server_id\").orderBy(\"status_time\")\n",
    "\n",
    "question_4 = question_4\\\n",
    ".withColumn('stop_time', lead(\"status_time\").over(question_4_window))\\\n",
    ".withColumn('diff', date_diff(col(\"stop_time\"),col(\"status_time\")))\\\n",
    ".filter(\"session_status = 'start' AND stop_time is not null\")\n",
    "\n",
    "\n",
    "answer_4 = question_4.agg(sum(col('diff')).alias('total_diff'))\n",
    "\n",
    "\n",
    "answer_4.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
